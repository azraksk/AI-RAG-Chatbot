{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497f92e2-8a65-4cb2-9220-7d4f46ff8927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from transformers import pipeline\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv('./data/Wikipedia_AI_Glossary.csv')\n",
    "df = df.dropna(subset=[\"Title\", \"Wikipedia_page_description\"])\n",
    "df[\"Wikipedia_page_description\"] = df[\"Wikipedia_page_description\"].apply(lambda x: x.replace(\"\\n\", \" \").strip())\n",
    "texts = df[\"Wikipedia_page_description\"].tolist()\n",
    "\n",
    "st.title(\"AI RAG Chatbot üåê\")\n",
    "st.write(\"Ask questions about AI, ML, Deep Learning, or related topics.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Embeddings\n",
    "# -------------------------------\n",
    "@st.cache_data\n",
    "def get_embeddings(texts):\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = embedder.encode(texts, show_progress_bar=True)\n",
    "    return embedder, embeddings\n",
    "\n",
    "embedder, embeddings = get_embeddings(texts)\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Chroma Vector Store\n",
    "# -------------------------------\n",
    "@st.cache_resource\n",
    "def create_vector_store(texts, embeddings):\n",
    "    client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "    # Eƒüer koleksiyon varsa sil\n",
    "    if \"ai_glossary\" in [c.name for c in client.list_collections()]:\n",
    "        client.delete_collection(\"ai_glossary\")\n",
    "    collection = client.create_collection(\"ai_glossary\")\n",
    "    for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "        collection.add(documents=[text], embeddings=[emb.tolist()], ids=[str(i)])\n",
    "    return collection\n",
    "\n",
    "collection = create_vector_store(texts, embeddings)\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ QA Model (Tiny Flan-T5)\n",
    "# -------------------------------\n",
    "@st.cache_resource\n",
    "def load_qa_model():\n",
    "    return pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", tokenizer=\"google/flan-t5-small\")\n",
    "\n",
    "qa_model = load_qa_model()\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ RAG Query\n",
    "# -------------------------------\n",
    "def rag_query(question, top_k=3):\n",
    "    query_vec = embedder.encode([question])\n",
    "    results = collection.query(query_embeddings=query_vec.tolist(), n_results=top_k)\n",
    "    top_docs = results[\"documents\"][0]\n",
    "    \n",
    "    # Contexti birle≈ütir ve token sƒ±nƒ±rlamasƒ± (~300 token)\n",
    "    context = \" \".join(top_docs)\n",
    "    context = context[:3000]  # Daha uzun context\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI expert. Answer the question using the following context.\n",
    "Provide a detailed explanation in 3-5 sentences.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "    answer = qa_model(prompt, max_new_tokens=600, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
    "    return answer.strip()\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ Streamlit UI\n",
    "# -------------------------------\n",
    "user_input = st.text_input(\"Your question:\")\n",
    "if user_input:\n",
    "    with st.spinner(\"Generating answer...\"):\n",
    "        answer = rag_query(user_input)\n",
    "    st.success(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85128731-1987-4668-a4e3-7b49f1956445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
